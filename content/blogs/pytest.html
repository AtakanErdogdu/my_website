---
title: "Predicting Direction of Stock Price Returns"
date: '2021-09-30'
description: Predicting Direction of Stock Price Returns
draft: no
image: stocks.jpg
keywords: ''
slug: pytest
categories:
- ''
- ''
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<pre class="python"><code>#Data manipulation
import pandas as pd
import numpy as np</code></pre>
<pre class="python"><code>
#Visualisation
import matplotlib.pyplot as plt
import seaborn as sns
plt.style.use(&#39;fivethirtyeight&#39;)</code></pre>
<pre class="python"><code>
#Data Preprocessing
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, MinMaxScaler, QuantileTransformer, RobustScaler, Normalizer, normalize
from sklearn.model_selection import train_test_split, TimeSeriesSplit, cross_val_score

from xgboost import XGBClassifier, plot_importance, Booster, plot_tree, to_graphviz

#Classifier
from sklearn.linear_model import LogisticRegression, Lasso, Ridge
import yfinance as yf

#Feature selection
from statsmodels.stats.outliers_influence import variance_inflation_factor

#Evaluation Metrics
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.metrics import plot_confusion_matrix, auc, roc_curve, plot_roc_curve, f1_score
from sklearn.metrics import mean_squared_error
import scikitplot as skplt

#Ignore warnings
import warnings
warnings.filterwarnings(&#39;ignore&#39;)</code></pre>
<pre class="python"><code>

#Load locally stored data for Johnson &amp; Johnson
df=pd.read_csv(&#39;JNJ.csv&#39;, index_col=0, parse_dates=True)

#Check whether there are any missing values
pd.DataFrame(df).isnull().sum()

#Calculate returns</code></pre>
<pre><code>## Open         0
## High         0
## Low          0
## Close        0
## Adj Close    0
## Volume       0
## dtype: int64</code></pre>
<pre class="python"><code>df[&#39;return&#39;]=np.log(df[&#39;Adj Close&#39;]).diff()

df.head()</code></pre>
<pre><code>##                  Open       High        Low  ...  Adj Close    Volume    return
## Date                                         ...                               
## 2001-05-16  48.750000  50.060001  48.450001  ...  29.521929  11319000       NaN
## 2001-05-17  49.799999  50.595001  49.450001  ...  29.791199   9944800  0.009080
## 2001-05-18  51.000000  51.000000  49.724998  ...  29.993113  11779600  0.006755
## 2001-05-21  50.250000  50.474998  49.665001  ...  29.883245   8086400 -0.003670
## 2001-05-22  50.320000  50.320000  49.375000  ...  29.399199   6592600 -0.016331
## 
## [5 rows x 7 columns]</code></pre>
<pre class="python"><code>
#Specifying features

#Set a counter for the for loop
cnts=5

#1-5 days lagged returns
for cnt in range (1,cnts+1):
    df[&#39;ret&#39;+str(cnt)]=df[&#39;return&#39;].shift(cnt)
    
#O-C &amp; H-L of t-1
df[&#39;O-C&#39;]=(df[&#39;Open&#39;]-df[&#39;Close&#39;]).shift(1)
df[&#39;H-L&#39;]=(df[&#39;High&#39;]-df[&#39;Low&#39;]).shift(1)

#Momentum 1-5 days
for cnt in range (1,cnts+1):
    #Shift 1 day to avoid data leakge
    df[&#39;momentum&#39;+str(cnt)]=(df[&#39;Adj Close&#39;]-df[&#39;Adj Close&#39;].shift(cnt)).shift(1)

#Moving average 5-10-15 days
for i in range (5,16,5):
    #Shift 1 day to avoid data leakage
    df[&#39;MA&#39;+str(i)]=(df[&#39;Adj Close&#39;].rolling(i).mean()).shift(1)
    
#Exponential moving average 5-10-15 days
for j in range(5,16,5):
    #Shift 1 day to avoid data leakage
    df[&#39;EMA&#39;+str(j)]=(df[&#39;Adj Close&#39;].ewm(j,adjust=False).mean()).shift(1)

#Define target, +1 if the price has increased (positive return), -1 if it has decreased (negative return)
df[&#39;Target&#39;]=np.sign(df[&#39;return&#39;].values)
#Treat 0 return signs as increase
df[&#39;Target&#39;]=df[&#39;Target&#39;].replace(0,1)
#Drop the columns except features and target
df=df.drop(columns=[&#39;Open&#39;,&#39;High&#39;,&#39;Low&#39;,&#39;Close&#39;,&#39;Volume&#39;],axis=1)


#Drop Nan values
df.dropna(inplace=True)
#Check output
df.head()</code></pre>
<pre><code>##             Adj Close    return      ret1  ...      EMA10      EMA15  Target
## Date                                       ...                              
## 2001-06-07  30.604868 -0.000388  0.008866  ...  29.516871  29.500788    -1.0
## 2001-06-08  30.293066 -0.010240 -0.000388  ...  29.615780  29.569793    -1.0
## 2001-06-11  30.102997 -0.006294 -0.010240  ...  29.677351  29.614998    -1.0
## 2001-06-12  30.230696  0.004233 -0.006294  ...  29.716046  29.645498     1.0
## 2001-06-13  30.117847 -0.003740  0.004233  ...  29.762833  29.682072    -1.0
## 
## [5 rows x 21 columns]</code></pre>
<pre class="python"><code>
#Define the features matrix X

X=df.drop(columns=[&#39;Adj Close&#39;, &#39;return&#39;, &#39;Target&#39;], axis=1)

#Define dependent variable
y=df[&#39;Target&#39;]
occurrences=np.count_nonzero(y==0)


#Split Data
X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.2,random_state=42,shuffle=False)
print(f&quot;Train and test size, respectively: {len(y_train)}, {len(y_test)}&quot;)

#Create a function that scales and fits the model</code></pre>
<pre><code>## Train and test size, respectively: 4012, 1004</code></pre>
<pre class="python"><code>def scale_fit(X_train, y_train,scaler,C,pen,solv):
    #Take input parameters
    scaler=scaler
    X_train=X_train
    y_train=y_train
    C=C
    pen=pen
    solv=solv
    #Fit and train
    logreg1=Pipeline([(&quot;scaler&quot;,scaler()),(&quot;regressor&quot;, LogisticRegression(C=C,penalty=pen,solver=solv))])
    logreg=logreg1.fit(X_train, y_train)
    scaledX=scaler().fit_transform(X_train)
    #Create a dictionary for output
    reg_dict={&quot;reg&quot;:logreg,&quot;Xs&quot;:scaledX}
    return reg_dict

#Perform L2 penalization; print out coefficients and R^2
l2reg = scale_fit(X_train,y_train,StandardScaler,1,&#39;l2&#39;,&#39;liblinear&#39;)
L2=l2reg[&quot;reg&quot;]
y_pred0=L2.predict(X_test)
print(f&quot;L2 regression train R^2: {L2.score(X_train,y_train):0.4}\n&quot;)</code></pre>
<pre><code>## L2 regression train R^2: 0.5282</code></pre>
<pre class="python"><code>print(f&quot;L2 regression test R^2: {L2.score(X_test,y_test):0.4}\n&quot;)</code></pre>
<pre><code>## L2 regression test R^2: 0.512</code></pre>
<pre class="python"><code>print(f&quot;L2 regression coefficients: {L2[&#39;regressor&#39;].coef_}\n&quot;)</code></pre>
<pre><code>## L2 regression coefficients: [[-0.00587078 -0.06502333 -0.06005368 -0.01825702 -0.21968662  0.06234216
##   -0.04355513 -0.02083411 -0.12530711  0.08676747 -0.34389893  0.45005928
##   -0.36389582 -0.37432105 -0.14073094 -0.21353786  0.25438636  0.85592707]]</code></pre>
<pre class="python"><code>print(f&quot;L2 regression MSE: {mean_squared_error(y_test,y_pred0)}&quot;)


#Perform L1 penalization; print out coefficients and R^2</code></pre>
<pre><code>## L2 regression MSE: 1.952191235059761</code></pre>
<pre class="python"><code>l1reg = scale_fit(X_train,y_train,StandardScaler,1,&#39;l1&#39;,&#39;liblinear&#39;)
L1=l1reg[&quot;reg&quot;]
y_pred1=L1.predict(X_test)
#Output accuracy
print(f&quot;L1 regression train R^2: {L1.score(X_train,y_train):0.4}\n&quot;)</code></pre>
<pre><code>## L1 regression train R^2: 0.5259</code></pre>
<pre class="python"><code>print(f&quot;L1 regression test R^2: {L1.score(X_test,y_test):0.4}\n&quot;)</code></pre>
<pre><code>## L1 regression test R^2: 0.5149</code></pre>
<pre class="python"><code>print(f&quot;L1 regression coefficients: {L1[&#39;regressor&#39;].coef_}\n&quot;)</code></pre>
<pre><code>## L1 regression coefficients: [[-0.00390108 -0.05941915 -0.036543   -0.02505308 -0.19726189  0.06456343
##   -0.03738196 -0.01511576 -0.09716659  0.03391093 -0.28310061  0.39674385
##   -0.33751056  0.          0.          0.          0.          0.35535445]]</code></pre>
<pre class="python"><code>print(f&quot;L1 regression MSE: {mean_squared_error(y_test,y_pred1)}&quot;)

#Plot the differences in coefficients</code></pre>
<pre><code>## L1 regression MSE: 1.9402390438247012</code></pre>
<pre class="python"><code>dfgr=pd.DataFrame(X.columns)
dfgr[&#39;L2 regression coefficients&#39;]=L2[&#39;regressor&#39;].coef_[0]
dfgr[&#39;L1 regression coefficients&#39;]=L1[&#39;regressor&#39;].coef_[0]
dfgr[&#39;Coefficients&#39;]=pd.DataFrame(X.columns)
dfgr.plot(x=&quot;Coefficients&quot;,y=[&#39;L2 regression coefficients&#39;,&#39;L1 regression coefficients&#39;],kind=&#39;bar&#39;,figsize=(13,5), title=&#39;Penalty Type and Regression Coefficients&#39;,fontsize=10,ylabel=&#39;Value&#39;)</code></pre>
<p><img src="/blogs/pytest_files/figure-html/unnamed-chunk-6-1.png" width="1248" style="display: block; margin: auto;" /></p>
<pre class="python"><code>
#Perform L1 penalization; use minmaxscaling, and print out coefficients and R^2
l1regminmax = scale_fit(X_train,y_train,MinMaxScaler,1,&#39;l1&#39;,&#39;liblinear&#39;)
L1m_m=l1regminmax[&quot;reg&quot;]
y_pred2=L1m_m.predict(X_test)
#Output accuracy
print(f&quot;L1 regression MinMaxScaled train R^2: {L1m_m.score(X_train,y_train):0.4}\n&quot;)</code></pre>
<pre><code>## L1 regression MinMaxScaled train R^2: 0.5209</code></pre>
<pre class="python"><code>print(f&quot;L1 regression MinMaxScaled test R^2: {L1m_m.score(X_test,y_test):0.4}\n&quot;)</code></pre>
<pre><code>## L1 regression MinMaxScaled test R^2: 0.5289</code></pre>
<pre class="python"><code>print(f&quot;L1 regression MinMaxScaled coefficients: {L1m_m[&#39;regressor&#39;].coef_}\n&quot;)</code></pre>
<pre><code>## L1 regression MinMaxScaled coefficients: [[ 0.          0.          0.18189106  0.          0.          0.7167046
##   -0.17193137  0.         -0.7695672   0.          0.          0.
##    0.          0.          0.          0.          0.          0.06231248]]</code></pre>
<pre class="python"><code>print(f&quot;L1 regression MinMaxScaled MSE: {mean_squared_error(y_test,y_pred2)}&quot;)

#Plot for selected features</code></pre>
<pre><code>## L1 regression MinMaxScaled MSE: 1.8844621513944224</code></pre>
<pre class="python"><code>Xscaled=l1regminmax[&quot;Xs&quot;]
a_s=[0,5,6,7,12,15]
head=list(X)
colors=[&#39;b&#39;,&#39;g&#39;,&#39;r&#39;,&#39;c&#39;,&#39;m&#39;,&#39;y&#39;]
for a in range (0,6):
    Xs=Xscaled[:,a_s[a]]
    headings=head[a_s[a]]
    plt.figure(figsize=(5,3))
    plt.hist(Xs, bins=&#39;auto&#39;, alpha=0.5, color=colors[a])
    plt.xlabel(&#39;Value&#39;, fontsize=10)
    plt.ylabel(&#39;Frequency&#39;,fontsize=10)
    plt.title(&#39;Scaled_&#39;+ str(headings),fontsize=10)
    plt.xlim([-1,1.5])
    plt.show()</code></pre>
<pre><code>## &lt;Figure size 500x300 with 0 Axes&gt;
## (array([  1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
##          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
##          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
##          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
##          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
##          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
##          0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,
##          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,
##          1.,   0.,   0.,   0.,   0.,   0.,   1.,   2.,   1.,   1.,   1.,
##          2.,   3.,   3.,   2.,   2.,   1.,   3.,   4.,   5.,   7.,   5.,
##         14.,  10.,  10.,  15.,  20.,  16.,  18.,  31.,  29.,  41.,  40.,
##         55.,  77.,  90., 105., 128., 148., 181., 248., 256., 305., 295.,
##        263., 254., 197., 193., 181., 140.,  97., 100.,  68.,  50.,  46.,
##         34.,  31.,  26.,  20.,  31.,  14.,  12.,   8.,   9.,   7.,   8.,
##         10.,   2.,   4.,   3.,   6.,   2.,   2.,   4.,   1.,   0.,   0.,
##          0.,   0.,   2.,   1.,   0.,   0.,   2.,   0.,   0.,   0.,   0.,
##          0.,   0.,   0.,   1.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,
##          0.,   0.,   0.,   0.,   1.,   0.,   1.,   0.,   0.,   0.,   0.,
##          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
##          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.]), array([0.        , 0.00456621, 0.00913242, 0.01369863, 0.01826484,
##        0.02283105, 0.02739726, 0.03196347, 0.03652968, 0.04109589,
##        0.0456621 , 0.05022831, 0.05479452, 0.05936073, 0.06392694,
##        0.06849315, 0.07305936, 0.07762557, 0.08219178, 0.08675799,
##        0.0913242 , 0.09589041, 0.10045662, 0.10502283, 0.10958904,
##        0.11415525, 0.11872146, 0.12328767, 0.12785388, 0.13242009,
##        0.1369863 , 0.14155251, 0.14611872, 0.15068493, 0.15525114,
##        0.15981735, 0.16438356, 0.16894977, 0.17351598, 0.17808219,
##        0.1826484 , 0.18721461, 0.19178082, 0.19634703, 0.20091324,
##        0.20547945, 0.21004566, 0.21461187, 0.21917808, 0.22374429,
##        0.2283105 , 0.23287671, 0.23744292, 0.24200913, 0.24657534,
##        0.25114155, 0.25570776, 0.26027397, 0.26484018, 0.26940639,
##        0.2739726 , 0.27853881, 0.28310502, 0.28767123, 0.29223744,
##        0.29680365, 0.30136986, 0.30593607, 0.31050228, 0.31506849,
##        0.3196347 , 0.32420091, 0.32876712, 0.33333333, 0.33789954,
##        0.34246575, 0.34703196, 0.35159817, 0.35616438, 0.36073059,
##        0.3652968 , 0.36986301, 0.37442922, 0.37899543, 0.38356164,
##        0.38812785, 0.39269406, 0.39726027, 0.40182648, 0.40639269,
##        0.4109589 , 0.41552511, 0.42009132, 0.42465753, 0.42922374,
##        0.43378995, 0.43835616, 0.44292237, 0.44748858, 0.45205479,
##        0.456621  , 0.46118721, 0.46575342, 0.47031963, 0.47488584,
##        0.47945205, 0.48401826, 0.48858447, 0.49315068, 0.49771689,
##        0.50228311, 0.50684932, 0.51141553, 0.51598174, 0.52054795,
##        0.52511416, 0.52968037, 0.53424658, 0.53881279, 0.543379  ,
##        0.54794521, 0.55251142, 0.55707763, 0.56164384, 0.56621005,
##        0.57077626, 0.57534247, 0.57990868, 0.58447489, 0.5890411 ,
##        0.59360731, 0.59817352, 0.60273973, 0.60730594, 0.61187215,
##        0.61643836, 0.62100457, 0.62557078, 0.63013699, 0.6347032 ,
##        0.63926941, 0.64383562, 0.64840183, 0.65296804, 0.65753425,
##        0.66210046, 0.66666667, 0.67123288, 0.67579909, 0.6803653 ,
##        0.68493151, 0.68949772, 0.69406393, 0.69863014, 0.70319635,
##        0.70776256, 0.71232877, 0.71689498, 0.72146119, 0.7260274 ,
##        0.73059361, 0.73515982, 0.73972603, 0.74429224, 0.74885845,
##        0.75342466, 0.75799087, 0.76255708, 0.76712329, 0.7716895 ,
##        0.77625571, 0.78082192, 0.78538813, 0.78995434, 0.79452055,
##        0.79908676, 0.80365297, 0.80821918, 0.81278539, 0.8173516 ,
##        0.82191781, 0.82648402, 0.83105023, 0.83561644, 0.84018265,
##        0.84474886, 0.84931507, 0.85388128, 0.85844749, 0.8630137 ,
##        0.86757991, 0.87214612, 0.87671233, 0.88127854, 0.88584475,
##        0.89041096, 0.89497717, 0.89954338, 0.90410959, 0.9086758 ,
##        0.91324201, 0.91780822, 0.92237443, 0.92694064, 0.93150685,
##        0.93607306, 0.94063927, 0.94520548, 0.94977169, 0.9543379 ,
##        0.95890411, 0.96347032, 0.96803653, 0.97260274, 0.97716895,
##        0.98173516, 0.98630137, 0.99086758, 0.99543379, 1.        ]), &lt;BarContainer object of 219 artists&gt;)
## Text(0.5, 0, &#39;Value&#39;)
## Text(0, 0.5, &#39;Frequency&#39;)
## Text(0.5, 1.0, &#39;Scaled_ret1&#39;)
## (-1.0, 1.5)
## &lt;Figure size 500x300 with 0 Axes&gt;
## (array([  1.,   0.,   0.,   1.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,
##          1.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   3.,
##          1.,   1.,   1.,   2.,   0.,   2.,   5.,   2.,   4.,   7.,   5.,
##         10.,  14.,   8.,   7.,  21.,  20.,  24.,  19.,  36.,  38.,  44.,
##         71.,  92.,  93., 117., 136., 168., 166., 219., 246., 293., 295.,
##        278., 238., 223., 220., 151., 135., 108.,  94.,  73.,  61.,  39.,
##         35.,  32.,  24.,  20.,  18.,  12.,  10.,  11.,  10.,   2.,   8.,
##          6.,   6.,   5.,   1.,   2.,   4.,   2.,   2.,   1.,   1.,   0.,
##          1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,
##          0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
##          0.,   0.,   0.,   0.,   1.,   1.]), array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,
##        0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.07758621,
##        0.0862069 , 0.09482759, 0.10344828, 0.11206897, 0.12068966,
##        0.12931034, 0.13793103, 0.14655172, 0.15517241, 0.1637931 ,
##        0.17241379, 0.18103448, 0.18965517, 0.19827586, 0.20689655,
##        0.21551724, 0.22413793, 0.23275862, 0.24137931, 0.25      ,
##        0.25862069, 0.26724138, 0.27586207, 0.28448276, 0.29310345,
##        0.30172414, 0.31034483, 0.31896552, 0.32758621, 0.3362069 ,
##        0.34482759, 0.35344828, 0.36206897, 0.37068966, 0.37931034,
##        0.38793103, 0.39655172, 0.40517241, 0.4137931 , 0.42241379,
##        0.43103448, 0.43965517, 0.44827586, 0.45689655, 0.46551724,
##        0.47413793, 0.48275862, 0.49137931, 0.5       , 0.50862069,
##        0.51724138, 0.52586207, 0.53448276, 0.54310345, 0.55172414,
##        0.56034483, 0.56896552, 0.57758621, 0.5862069 , 0.59482759,
##        0.60344828, 0.61206897, 0.62068966, 0.62931034, 0.63793103,
##        0.64655172, 0.65517241, 0.6637931 , 0.67241379, 0.68103448,
##        0.68965517, 0.69827586, 0.70689655, 0.71551724, 0.72413793,
##        0.73275862, 0.74137931, 0.75      , 0.75862069, 0.76724138,
##        0.77586207, 0.78448276, 0.79310345, 0.80172414, 0.81034483,
##        0.81896552, 0.82758621, 0.8362069 , 0.84482759, 0.85344828,
##        0.86206897, 0.87068966, 0.87931034, 0.88793103, 0.89655172,
##        0.90517241, 0.9137931 , 0.92241379, 0.93103448, 0.93965517,
##        0.94827586, 0.95689655, 0.96551724, 0.97413793, 0.98275862,
##        0.99137931, 1.        ]), &lt;BarContainer object of 116 artists&gt;)
## Text(0.5, 0, &#39;Value&#39;)
## Text(0, 0.5, &#39;Frequency&#39;)
## Text(0.5, 1.0, &#39;Scaled_O-C&#39;)
## (-1.0, 1.5)
## &lt;Figure size 500x300 with 0 Axes&gt;
## (array([ 17.,  46., 139., 243., 250., 324., 268., 363., 288., 275., 278.,
##        218., 179., 132., 137., 108., 105.,  95.,  73.,  56.,  52.,  42.,
##         43.,  30.,  29.,  27.,  32.,  18.,  16.,  11.,  14.,  10.,  12.,
##          6.,   8.,   6.,   5.,   5.,   9.,   5.,   3.,   1.,   2.,   2.,
##          2.,   1.,   4.,   1.,   0.,   2.,   1.,   1.,   1.,   1.,   1.,
##          1.,   0.,   0.,   1.,   1.,   0.,   1.,   0.,   2.,   1.,   0.,
##          0.,   1.,   0.,   0.,   1.,   0.,   0.,   0.,   2.,   2.,   0.,
##          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
##          0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,
##          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
##          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
##          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
##          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
##          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
##          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
##          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
##          0.,   0.,   0.,   0.,   0.,   1.]), array([0.        , 0.00549451, 0.01098901, 0.01648352, 0.02197802,
##        0.02747253, 0.03296703, 0.03846154, 0.04395604, 0.04945055,
##        0.05494505, 0.06043956, 0.06593407, 0.07142857, 0.07692308,
##        0.08241758, 0.08791209, 0.09340659, 0.0989011 , 0.1043956 ,
##        0.10989011, 0.11538462, 0.12087912, 0.12637363, 0.13186813,
##        0.13736264, 0.14285714, 0.14835165, 0.15384615, 0.15934066,
##        0.16483516, 0.17032967, 0.17582418, 0.18131868, 0.18681319,
##        0.19230769, 0.1978022 , 0.2032967 , 0.20879121, 0.21428571,
##        0.21978022, 0.22527473, 0.23076923, 0.23626374, 0.24175824,
##        0.24725275, 0.25274725, 0.25824176, 0.26373626, 0.26923077,
##        0.27472527, 0.28021978, 0.28571429, 0.29120879, 0.2967033 ,
##        0.3021978 , 0.30769231, 0.31318681, 0.31868132, 0.32417582,
##        0.32967033, 0.33516484, 0.34065934, 0.34615385, 0.35164835,
##        0.35714286, 0.36263736, 0.36813187, 0.37362637, 0.37912088,
##        0.38461538, 0.39010989, 0.3956044 , 0.4010989 , 0.40659341,
##        0.41208791, 0.41758242, 0.42307692, 0.42857143, 0.43406593,
##        0.43956044, 0.44505495, 0.45054945, 0.45604396, 0.46153846,
##        0.46703297, 0.47252747, 0.47802198, 0.48351648, 0.48901099,
##        0.49450549, 0.5       , 0.50549451, 0.51098901, 0.51648352,
##        0.52197802, 0.52747253, 0.53296703, 0.53846154, 0.54395604,
##        0.54945055, 0.55494505, 0.56043956, 0.56593407, 0.57142857,
##        0.57692308, 0.58241758, 0.58791209, 0.59340659, 0.5989011 ,
##        0.6043956 , 0.60989011, 0.61538462, 0.62087912, 0.62637363,
##        0.63186813, 0.63736264, 0.64285714, 0.64835165, 0.65384615,
##        0.65934066, 0.66483516, 0.67032967, 0.67582418, 0.68131868,
##        0.68681319, 0.69230769, 0.6978022 , 0.7032967 , 0.70879121,
##        0.71428571, 0.71978022, 0.72527473, 0.73076923, 0.73626374,
##        0.74175824, 0.74725275, 0.75274725, 0.75824176, 0.76373626,
##        0.76923077, 0.77472527, 0.78021978, 0.78571429, 0.79120879,
##        0.7967033 , 0.8021978 , 0.80769231, 0.81318681, 0.81868132,
##        0.82417582, 0.82967033, 0.83516484, 0.84065934, 0.84615385,
##        0.85164835, 0.85714286, 0.86263736, 0.86813187, 0.87362637,
##        0.87912088, 0.88461538, 0.89010989, 0.8956044 , 0.9010989 ,
##        0.90659341, 0.91208791, 0.91758242, 0.92307692, 0.92857143,
##        0.93406593, 0.93956044, 0.94505495, 0.95054945, 0.95604396,
##        0.96153846, 0.96703297, 0.97252747, 0.97802198, 0.98351648,
##        0.98901099, 0.99450549, 1.        ]), &lt;BarContainer object of 182 artists&gt;)
## Text(0.5, 0, &#39;Value&#39;)
## Text(0, 0.5, &#39;Frequency&#39;)
## Text(0.5, 1.0, &#39;Scaled_H-L&#39;)
## (-1.0, 1.5)
## &lt;Figure size 500x300 with 0 Axes&gt;
## (array([  1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,
##          0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,
##          1.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   1.,   0.,   0.,
##          0.,   0.,   0.,   3.,   1.,   1.,   0.,   2.,   3.,   3.,   7.,
##          3.,   4.,   5.,   5.,   3.,   6.,   4.,   9.,   8.,  13.,  14.,
##         14.,  12.,  18.,  21.,  26.,  37.,  42.,  48.,  58.,  65.,  87.,
##        120., 151., 171., 206., 249., 257., 322., 274., 258., 227., 219.,
##        182., 122., 126.,  91.,  72.,  77.,  60.,  42.,  34.,  30.,  42.,
##         25.,  20.,  10.,  16.,  11.,   8.,   8.,   8.,   6.,   7.,   6.,
##          5.,   1.,   3.,   2.,   0.,   3.,   1.,   1.,   2.,   1.,   0.,
##          1.,   0.,   0.,   0.,   0.,   2.,   0.,   1.,   0.,   1.,   0.,
##          0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   1.,   0.,
##          0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,
##          0.,   1.]), array([0.        , 0.00689655, 0.0137931 , 0.02068966, 0.02758621,
##        0.03448276, 0.04137931, 0.04827586, 0.05517241, 0.06206897,
##        0.06896552, 0.07586207, 0.08275862, 0.08965517, 0.09655172,
##        0.10344828, 0.11034483, 0.11724138, 0.12413793, 0.13103448,
##        0.13793103, 0.14482759, 0.15172414, 0.15862069, 0.16551724,
##        0.17241379, 0.17931034, 0.1862069 , 0.19310345, 0.2       ,
##        0.20689655, 0.2137931 , 0.22068966, 0.22758621, 0.23448276,
##        0.24137931, 0.24827586, 0.25517241, 0.26206897, 0.26896552,
##        0.27586207, 0.28275862, 0.28965517, 0.29655172, 0.30344828,
##        0.31034483, 0.31724138, 0.32413793, 0.33103448, 0.33793103,
##        0.34482759, 0.35172414, 0.35862069, 0.36551724, 0.37241379,
##        0.37931034, 0.3862069 , 0.39310345, 0.4       , 0.40689655,
##        0.4137931 , 0.42068966, 0.42758621, 0.43448276, 0.44137931,
##        0.44827586, 0.45517241, 0.46206897, 0.46896552, 0.47586207,
##        0.48275862, 0.48965517, 0.49655172, 0.50344828, 0.51034483,
##        0.51724138, 0.52413793, 0.53103448, 0.53793103, 0.54482759,
##        0.55172414, 0.55862069, 0.56551724, 0.57241379, 0.57931034,
##        0.5862069 , 0.59310345, 0.6       , 0.60689655, 0.6137931 ,
##        0.62068966, 0.62758621, 0.63448276, 0.64137931, 0.64827586,
##        0.65517241, 0.66206897, 0.66896552, 0.67586207, 0.68275862,
##        0.68965517, 0.69655172, 0.70344828, 0.71034483, 0.71724138,
##        0.72413793, 0.73103448, 0.73793103, 0.74482759, 0.75172414,
##        0.75862069, 0.76551724, 0.77241379, 0.77931034, 0.7862069 ,
##        0.79310345, 0.8       , 0.80689655, 0.8137931 , 0.82068966,
##        0.82758621, 0.83448276, 0.84137931, 0.84827586, 0.85517241,
##        0.86206897, 0.86896552, 0.87586207, 0.88275862, 0.88965517,
##        0.89655172, 0.90344828, 0.91034483, 0.91724138, 0.92413793,
##        0.93103448, 0.93793103, 0.94482759, 0.95172414, 0.95862069,
##        0.96551724, 0.97241379, 0.97931034, 0.9862069 , 0.99310345,
##        1.        ]), &lt;BarContainer object of 145 artists&gt;)
## Text(0.5, 0, &#39;Value&#39;)
## Text(0, 0.5, &#39;Frequency&#39;)
## Text(0.5, 1.0, &#39;Scaled_momentum1&#39;)
## (-1.0, 1.5)
## &lt;Figure size 500x300 with 0 Axes&gt;
## (array([ 74., 483., 399., 559., 677., 390., 204., 123.,  30.,  28.,  19.,
##         72.,  54., 106.,  56., 206., 172.,  56.,  32.,  40.,  90.,  58.,
##         54.,  30.]), array([0.        , 0.04166667, 0.08333333, 0.125     , 0.16666667,
##        0.20833333, 0.25      , 0.29166667, 0.33333333, 0.375     ,
##        0.41666667, 0.45833333, 0.5       , 0.54166667, 0.58333333,
##        0.625     , 0.66666667, 0.70833333, 0.75      , 0.79166667,
##        0.83333333, 0.875     , 0.91666667, 0.95833333, 1.        ]), &lt;BarContainer object of 24 artists&gt;)
## Text(0.5, 0, &#39;Value&#39;)
## Text(0, 0.5, &#39;Frequency&#39;)
## Text(0.5, 1.0, &#39;Scaled_MA5&#39;)
## (-1.0, 1.5)
## &lt;Figure size 500x300 with 0 Axes&gt;
## (array([291., 511., 397., 735., 513., 331.,  83.,  68.,  27.,  25.,  44.,
##         65., 102.,  48.,  81., 268., 117.,  29.,  20.,  85.,  81.,  42.,
##         49.]), array([0.        , 0.04347826, 0.08695652, 0.13043478, 0.17391304,
##        0.2173913 , 0.26086957, 0.30434783, 0.34782609, 0.39130435,
##        0.43478261, 0.47826087, 0.52173913, 0.56521739, 0.60869565,
##        0.65217391, 0.69565217, 0.73913043, 0.7826087 , 0.82608696,
##        0.86956522, 0.91304348, 0.95652174, 1.        ]), &lt;BarContainer object of 23 artists&gt;)
## Text(0.5, 0, &#39;Value&#39;)
## Text(0, 0.5, &#39;Frequency&#39;)
## Text(0.5, 1.0, &#39;Scaled_EMA5&#39;)
## (-1.0, 1.5)</code></pre>
<p><img src="/blogs/pytest_files/figure-html/unnamed-chunk-7-3.png" width="480" style="display: block; margin: auto;" /><img src="/blogs/pytest_files/figure-html/unnamed-chunk-7-4.png" width="480" style="display: block; margin: auto;" /><img src="/blogs/pytest_files/figure-html/unnamed-chunk-7-5.png" width="480" style="display: block; margin: auto;" /><img src="/blogs/pytest_files/figure-html/unnamed-chunk-7-6.png" width="480" style="display: block; margin: auto;" /><img src="/blogs/pytest_files/figure-html/unnamed-chunk-7-7.png" width="480" style="display: block; margin: auto;" /><img src="/blogs/pytest_files/figure-html/unnamed-chunk-7-8.png" width="480" style="display: block; margin: auto;" /></p>
<pre class="python"><code>
#Perform L1 penalization; scale to [0,1] range
l1normalizer = scale_fit(X_train,y_train,QuantileTransformer,1,&#39;l1&#39;,&#39;liblinear&#39;)
L1n=l1normalizer[&quot;reg&quot;]
y_pred3=L1n.predict(X_test)
#Output accuracy, MSE, and coefficients
print(f&quot;L1 [0,1] scaled  regression train R^2: {L1n.score(X_train,y_train):0.4}\n&quot;)</code></pre>
<pre><code>## L1 [0,1] scaled  regression train R^2: 0.5242</code></pre>
<pre class="python"><code>print(f&quot;L1 [0,1] scaled regression test R^2: {L1n.score(X_test,y_test):0.4}\n&quot;)</code></pre>
<pre><code>## L1 [0,1] scaled regression test R^2: 0.493</code></pre>
<pre class="python"><code>print(f&quot;L1 [0,1] scaled regression coefficients: {L1n[&#39;regressor&#39;].coef_}\n&quot;)</code></pre>
<pre><code>## L1 [0,1] scaled regression coefficients: [[ 0.         -0.1920609   0.20184964  0.13874241 -0.08346254  0.22459344
##   -0.05385142 -0.20041674  0.2471537   0.         -0.16905348  0.
##    0.          0.          0.          0.          0.          0.0160389 ]]</code></pre>
<pre class="python"><code>print(f&quot;L1 [0,1] scaled regression MSE: {mean_squared_error(y_test,y_pred3)}&quot;)

#Plot for selected features</code></pre>
<pre><code>## L1 [0,1] scaled regression MSE: 2.0278884462151394</code></pre>
<pre class="python"><code>Xscaled2=l1normalizer[&quot;Xs&quot;]
for a in range (0,6):
    Xs=Xscaled2[:,a_s[a]]
    headings=head[a_s[a]]
    plt.figure(figsize=(5,3))
    plt.hist(Xs, bins=&#39;auto&#39;, alpha=0.5, color=colors[a])
    plt.xlabel(&#39;Value&#39;, fontsize=10)
    plt.ylabel(&#39;Frequency&#39;,fontsize=10)
    plt.title(&#39;Scaled_&#39;+ str(headings),fontsize=10)
    plt.xlim([-1,1.5])
    plt.show()</code></pre>
<pre><code>## &lt;Figure size 500x300 with 0 Axes&gt;
## (array([251., 250., 252., 250., 251., 251., 250., 251., 250., 252., 250.,
##        252., 250., 251., 250., 251.]), array([0.    , 0.0625, 0.125 , 0.1875, 0.25  , 0.3125, 0.375 , 0.4375,
##        0.5   , 0.5625, 0.625 , 0.6875, 0.75  , 0.8125, 0.875 , 0.9375,
##        1.    ]), &lt;BarContainer object of 16 artists&gt;)
## Text(0.5, 0, &#39;Value&#39;)
## Text(0, 0.5, &#39;Frequency&#39;)
## Text(0.5, 1.0, &#39;Scaled_ret1&#39;)
## (-1.0, 1.5)
## &lt;Figure size 500x300 with 0 Axes&gt;
## (array([251., 248., 253., 250., 252., 250., 253., 247., 253., 251., 247.,
##        254., 248., 254., 249., 252.]), array([0.    , 0.0625, 0.125 , 0.1875, 0.25  , 0.3125, 0.375 , 0.4375,
##        0.5   , 0.5625, 0.625 , 0.6875, 0.75  , 0.8125, 0.875 , 0.9375,
##        1.    ]), &lt;BarContainer object of 16 artists&gt;)
## Text(0.5, 0, &#39;Value&#39;)
## Text(0, 0.5, &#39;Frequency&#39;)
## Text(0.5, 1.0, &#39;Scaled_O-C&#39;)
## (-1.0, 1.5)
## &lt;Figure size 500x300 with 0 Axes&gt;
## (array([246., 256., 253., 248., 254., 253., 244., 251., 255., 249., 248.,
##        250., 250., 254., 250., 251.]), array([0.    , 0.0625, 0.125 , 0.1875, 0.25  , 0.3125, 0.375 , 0.4375,
##        0.5   , 0.5625, 0.625 , 0.6875, 0.75  , 0.8125, 0.875 , 0.9375,
##        1.    ]), &lt;BarContainer object of 16 artists&gt;)
## Text(0.5, 0, &#39;Value&#39;)
## Text(0, 0.5, &#39;Frequency&#39;)
## Text(0.5, 1.0, &#39;Scaled_H-L&#39;)
## (-1.0, 1.5)
## &lt;Figure size 500x300 with 0 Axes&gt;
## (array([253., 249., 251., 251., 250., 251., 250., 251., 251., 250., 251.,
##        251., 249., 252., 250., 252.]), array([0.    , 0.0625, 0.125 , 0.1875, 0.25  , 0.3125, 0.375 , 0.4375,
##        0.5   , 0.5625, 0.625 , 0.6875, 0.75  , 0.8125, 0.875 , 0.9375,
##        1.    ]), &lt;BarContainer object of 16 artists&gt;)
## Text(0.5, 0, &#39;Value&#39;)
## Text(0, 0.5, &#39;Frequency&#39;)
## Text(0.5, 1.0, &#39;Scaled_momentum1&#39;)
## (-1.0, 1.5)
## &lt;Figure size 500x300 with 0 Axes&gt;
## (array([251., 251., 250., 251., 251., 252., 249., 251., 251., 251., 249.,
##        255., 248., 251., 248., 253.]), array([0.    , 0.0625, 0.125 , 0.1875, 0.25  , 0.3125, 0.375 , 0.4375,
##        0.5   , 0.5625, 0.625 , 0.6875, 0.75  , 0.8125, 0.875 , 0.9375,
##        1.    ]), &lt;BarContainer object of 16 artists&gt;)
## Text(0.5, 0, &#39;Value&#39;)
## Text(0, 0.5, &#39;Frequency&#39;)
## Text(0.5, 1.0, &#39;Scaled_MA5&#39;)
## (-1.0, 1.5)
## &lt;Figure size 500x300 with 0 Axes&gt;
## (array([251., 251., 251., 251., 249., 252., 250., 251., 251., 251., 250.,
##        251., 251., 250., 250., 252.]), array([0.    , 0.0625, 0.125 , 0.1875, 0.25  , 0.3125, 0.375 , 0.4375,
##        0.5   , 0.5625, 0.625 , 0.6875, 0.75  , 0.8125, 0.875 , 0.9375,
##        1.    ]), &lt;BarContainer object of 16 artists&gt;)
## Text(0.5, 0, &#39;Value&#39;)
## Text(0, 0.5, &#39;Frequency&#39;)
## Text(0.5, 1.0, &#39;Scaled_EMA5&#39;)
## (-1.0, 1.5)</code></pre>
<p><img src="/blogs/pytest_files/figure-html/unnamed-chunk-8-15.png" width="480" style="display: block; margin: auto;" /><img src="/blogs/pytest_files/figure-html/unnamed-chunk-8-16.png" width="480" style="display: block; margin: auto;" /><img src="/blogs/pytest_files/figure-html/unnamed-chunk-8-17.png" width="480" style="display: block; margin: auto;" /><img src="/blogs/pytest_files/figure-html/unnamed-chunk-8-18.png" width="480" style="display: block; margin: auto;" /><img src="/blogs/pytest_files/figure-html/unnamed-chunk-8-19.png" width="480" style="display: block; margin: auto;" /><img src="/blogs/pytest_files/figure-html/unnamed-chunk-8-20.png" width="480" style="display: block; margin: auto;" /></p>
<pre class="python"><code>
#Get the X axis headings
dfgr1=pd.DataFrame(X.columns)
dfgr1[&#39;L1 regression StandardScaled coefficients&#39;]=L1[&#39;regressor&#39;].coef_[0]
dfgr1[&#39;L1 regression MinMaxScaled coefficients&#39;] =L1m_m[&#39;regressor&#39;].coef_[0]
dfgr1[&#39;L1 regression uniform [0,1] scaled coefficients&#39;] =L1n[&#39;regressor&#39;].coef_[0]
dfgr1[&#39;Coefficients&#39;]=pd.DataFrame(X.columns)
dfgr1.plot(x=&quot;Coefficients&quot;,y=[&#39;L1 regression StandardScaled coefficients&#39;,&#39;L1 regression MinMaxScaled coefficients&#39;,&#39;L1 regression uniform [0,1] scaled coefficients&#39;],kind=&#39;bar&#39;,figsize=(13,5), title=&#39;Scaling Type &amp; Coefficients&#39;,fontsize=10,ylabel=&#39;Value&#39;)
plt.legend(loc=&#39;upper right&#39;,fontsize=8)
plt.show()</code></pre>
<p><img src="/blogs/pytest_files/figure-html/unnamed-chunk-9-27.png" width="1248" style="display: block; margin: auto;" /></p>
<pre class="python"><code>

#Feature Selection with f-test
from sklearn.feature_selection import f_regression, SelectKBest, SelectPercentile, f_classif

#Show f-scores of each feature, take k=5 for an example
method=SelectKBest(f_classif, k=5)
method.fit(X,y)</code></pre>
<pre><code>## SelectKBest(k=5)</code></pre>
<pre class="python"><code>method.get_support(indices=True)</code></pre>
<pre><code>## array([ 0,  5,  7,  8, 10], dtype=int64)</code></pre>
<pre class="python"><code>for f,s in zip(X.columns,method.scores_):
    print(f&#39;F-score: {s:0.4} for feature {f}&#39;)</code></pre>
<pre><code>## F-score: 8.292 for feature ret1
## F-score: 2.307 for feature ret2
## F-score: 0.4462 for feature ret3
## F-score: 0.1856 for feature ret4
## F-score: 0.04016 for feature ret5
## F-score: 4.725 for feature O-C
## F-score: 0.01164 for feature H-L
## F-score: 6.389 for feature momentum1
## F-score: 5.646 for feature momentum2
## F-score: 2.586 for feature momentum3
## F-score: 3.965 for feature momentum4
## F-score: 1.856 for feature momentum5
## F-score: 1.344 for feature MA5
## F-score: 1.387 for feature MA10
## F-score: 1.45 for feature MA15
## F-score: 1.398 for feature EMA5
## F-score: 1.498 for feature EMA10
## F-score: 1.582 for feature EMA15</code></pre>
<pre class="python"><code>
#Create a dictionary to calibrate the number of features based on f-score
kselectordict={0:&quot;ret1&quot;,1:&quot;ret2&quot;,2:&quot;ret3&quot;,3:&quot;ret4&quot;,4:&quot;ret5&quot;,5:&quot;O-C&quot;,6:&quot;H-L&quot;,7:&quot;momentum1&quot;,8:&quot;momentum2&quot;,9:&quot;momentum3&quot;,10:&quot;momentum4&quot;,11:&quot;momentum5&quot;,12:&quot;MA5&quot;,13:&quot;MA10&quot;,14:&quot;MA15&quot;,15:&quot;EMA5&quot;,16:&quot;EMA10&quot;,17:&quot;EMA15&quot;}
#Conduct selection based on f-statistic and return the feature matrix
def k_selector(X,y,kselectordict,n):
    X_method2=pd.DataFrame()
    X=X
    y=y
    method2=SelectKBest(f_regression,k=n)
    method2.fit(X,y)
    keys=method2.get_support(indices=True)
    #For the chosen features, create a new feature matrix and assign the correct values
    for key in keys:
        X_method2[kselectordict[key]]=X[kselectordict[key]]
    #Return the new feature matrix 
    return X_method2</code></pre>
<pre class="python"><code>
#Optimizing
#Create an array to calibrate the hyperparameters C and k
storage=np.array([[0,0,0]])
#Create a counter for iteration to find the optimal C and k that minimise MSE
#For each k
for n in range(3,15,1):
    X_method2=k_selector(X,y,kselectordict,n)
    X_train2, X_test2, y_train2, y_test2 = train_test_split(X_method2,y,test_size=0.2,random_state=42,shuffle=False)
    #For each C between 0.01 and 1 C
    for i in range(1,101,1):
        reducedvar=scale_fit(X_train2,y_train2,MinMaxScaler,i/100,&#39;l2&#39;,&#39;liblinear&#39;)
        redvar=reducedvar[&quot;reg&quot;]
        y_pred5=redvar.predict(X_test2)
        mse=mean_squared_error(y_test2,y_pred5)
        mse_i=np.vstack([[mse,i/100,n]])
        #Stack mse, C, and k highest f scored features
        storage=np.vstack((storage,mse_i))

#Delete the inital 0 row
storage=np.delete(storage,(0),axis=0)
#Rounding
storage=np.round(storage,4)
#Find the minimum MSE in the iterations with different C and k
min_mse=np.amin(storage,axis=0)
min_mse</code></pre>
<pre><code>## array([1.8048, 0.01  , 3.    ])</code></pre>
<pre class="python"><code>
#Create a counter to find the index of the lowest MSE model 
i=0
j=0
#Iterate the 1200 rows of storage array
while i&lt;1200:
    a=storage[:,0][i]
    if a==1.8048:
        j=i
        i=i+1
    else:
        i=i+1
#The MSE, C, and k for the lowest MSE model
m=storage[j]
m</code></pre>
<pre><code>## array([1.8048, 0.08  , 3.    ])</code></pre>
<pre class="python"><code>
#Rerun the optimal model to print out coefficients, MSE, and R^2
X_reducedvar=k_selector(X,y,kselectordict,int(m[2]))
X_trainrv, X_testrv, y_trainrv, y_testrv = train_test_split(X_reducedvar,y,test_size=0.2,random_state=42,shuffle=False)
#Fit and train using local scale_fit function
reducedvar=scale_fit(X_trainrv,y_trainrv,MinMaxScaler,m[1],&#39;l2&#39;,&#39;liblinear&#39;)
redvar=reducedvar[&quot;reg&quot;]
#Predict
y_predrv=redvar.predict(X_testrv)
print(f&quot;L2 regression lower variance test R^2: {redvar.score(X_testrv,y_testrv):0.4}\n&quot;)</code></pre>
<pre><code>## L2 regression lower variance test R^2: 0.5488</code></pre>
<pre class="python"><code>print(f&quot;L2 regression lower variance MSE: {mean_squared_error(y_testrv,y_predrv)}\n&quot;)</code></pre>
<pre><code>## L2 regression lower variance MSE: 1.8047808764940239</code></pre>
<pre class="python"><code>print(f&quot;These are all of the coefficients of the lowest MSE model:\n&quot;)
#For each feature, print out the coefficient</code></pre>
<pre><code>## These are all of the coefficients of the lowest MSE model:</code></pre>
<pre class="python"><code>for i in range(0,int(m[2]),1):
    print(f&quot;L2 regression lower variance coefficient of {list(X_reducedvar.columns)[i]} is: {redvar[&#39;regressor&#39;].coef_[0][i]}\n&quot;)</code></pre>
<pre><code>## L2 regression lower variance coefficient of ret1 is: -0.011650941110158294
## 
## L2 regression lower variance coefficient of momentum1 is: -0.1403073755521498
## 
## L2 regression lower variance coefficient of momentum2 is: -0.26953264653111064</code></pre>
<pre class="python"><code>
#Classification report
print(classification_report(y_testrv,y_predrv))</code></pre>
<pre><code>##               precision    recall  f1-score   support
## 
##         -1.0       0.53      0.19      0.28       463
##          1.0       0.55      0.86      0.67       541
## 
##     accuracy                           0.55      1004
##    macro avg       0.54      0.52      0.47      1004
## weighted avg       0.54      0.55      0.49      1004</code></pre>
<pre class="python"><code>f_measure=f1_score(y_testrv,y_predrv)
f_measure</code></pre>
<pre><code>## 0.6724511930585683</code></pre>
<pre class="python"><code>
probs=redvar.predict_proba(X_testrv)

preds1 = probs[:, 0]
preds2 = probs[:, 1]

fpr1, tpr1, threshold1 = roc_curve(y_testrv, preds1, pos_label=-1)
roc_auc1 = auc(fpr1, tpr1)

fpr2, tpr2, threshold2 = roc_curve(y_testrv, preds2, pos_label=1)
roc_auc2 = auc(fpr2, tpr2)

pltt=plt.figure(figsize=(5,3))
ax1=plt.axes()
ax1.plot([0, 1], [0, 1], &#39;r--&#39;)
ax1.plot(fpr1, tpr1, &#39;cornflowerblue&#39;, label=f&#39;ROC Curve of Class -1 Area = {roc_auc1:0.3}&#39;)
ax1.set_title(&quot;Receiver Operating Characteristic for Down Moves&quot;)
ax1.set_xlabel(&#39;False Positive Rate&#39;,fontsize=13)
ax1.set_ylabel(&#39;True Positive Rate&#39;,fontsize=13)
ax1.legend();
plt.show()</code></pre>
<p><img src="/blogs/pytest_files/figure-html/unnamed-chunk-16-29.png" width="480" style="display: block; margin: auto;" /></p>
